{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wxsaxk7FSkmh",
        "3ClX3MgbLn2m",
        "mJxlhR-PHc4M",
        "rBsWMz-fIEaW",
        "feerSPFJI4UV",
        "H-B-4e3gJWp2",
        "B4IHd-IqdvT1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgustinBatistelli/programacion_concurrente/blob/master/Ejercicio_1_OpenMP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th1ZsKBrRMrn"
      },
      "source": [
        "# Programacion Concurrente - TP2 - Parte 1\n",
        "\n",
        "Utilizamos 2 prácticas con OpenMP desarrolladas en lenguaje C/C++ nativo en plataforma colab. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtuoNACar7c-"
      },
      "source": [
        "---\n",
        "## 1.1. Ejercicio 1 - Hola Mundo estilo Programacion Concurrente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1. Preguntas ejercicio 1:\n",
        "\n",
        "a) Identifique los 3 componentes de openMP en el ejercicio 1.\n",
        "\n",
        "b) Realice pruebas modificando la cantidad de hilos (1, 3, 7). Que conclusiones pudo determinar?.\n",
        "\n",
        "c) ¿Cuál es la diferencia las formas de asignación *static* y *dynamic* en la cláusula *schedule*?, ¿Qué sucede si utiliza *dynamic* en el código?\n",
        "\n",
        "d) En el for: ¿Que sucede con el valor de j, sí se parametriza como lastprivate?\n"
      ],
      "metadata": {
        "id": "apisS7HOLQqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respuestas ejercicio 1:\n",
        "\n",
        "a) \n",
        "Directivas al compilador: parallel, single, master, for.\n",
        "\n",
        "Funciones de biblioteca: omp_get_thread_num(), omp_get_num_threads(), omp_get_num_procs() .\n",
        "\n",
        "Variables de entorno: OMP_NUM_THREADS.\n",
        "\n",
        "b) \n",
        "No importa con cuantos hilos ejecute el proceso, el número de procesadores de colab siempre me devuelve 2. En cada una de las ejecuciones que se intentaron, sin importar el número especificado de hilos (con la forma de asignación dynamic) es el hilo que ejecuta primero el for el que toma la mayor cantidad de registros. Al ejecutar para 1, 2 y 3 hilos, apenas 4 registros son tomados por un hilo diferente al que comenzó la ejecución. Es agregando más hilos donde las posibilidades de tener a más hilos ejecutando tareas en el for es mayor. \n",
        "\n",
        "c) \n",
        "En ambos tipos de asignación, se reparten las ejecuciones entre los threads. \n",
        "Si se utiliza la asignación static, las ejecuciones de cada thread se reparten antes de entrar al bucle. El valor del chunk es el que define cuantos valores se ejecutan por cada thread. El for llega hasta 20 iteraciones, y el chunk identifica 5 para cada thread. Si se usan 4 threads, cada uno ejecutará 5 veces. Si se definen menos de 4, cada hilo ejecutará como mínimo 5 veces, y luego se repartirán de 5 en 5 las ejecuciones restantes. (Si tengo 3 hilos, los hilos 0, 1 y 2 ejecutarán los primeros 15; y luego el hilo 0 ejecutará los restantes 5). Si utilizo más de 4 hilos, serán los primeros 4 en ser creados los que ejecutarán los valores. Dado a que está definido que como mínimo deben tomar 5, habrá hilos que no podrán ejecutar una iteración del for.\n",
        "Si se utiliza la asignación dynamic, a los threads se les puede definir con el chunk cuantos datos ejecutar, pero una vez que hayan tomado los que les correspondían, pueden tomar incluso más. Por ejemplo, en una ejecución con 5 hilos, el hilo 2 tomó diez valores, el hilo 3 tomó cinco valores y el hilo 4 tomó otros cinco. La repartición no es de forma equitativa antes de empezar el proceso, dado a que los hilos 0 y 1 no ejecutaron ningún valor. \n",
        "\n",
        "d) \n",
        "Si se parametriza j como lastprivate, cada uno de los hilos tendrá una copia de la variable. Y la variable j global quedará actualizada con el valor que le dio el último hilo en ejecución. En caso de que el último hilo le asigne 5, ese será su valor al finalizar la ejecución. "
      ],
      "metadata": {
        "id": "QA8p66m7oK_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2. Código Lenguaje C "
      ],
      "metadata": {
        "id": "QQDtKmswLVOm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEbO8EXWm4mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca630254-34e1-4307-9018-4236cf42e61c"
      },
      "source": [
        "%%writefile code.cpp\n",
        "\n",
        "// Hola Mundo desde OpenMP, usando c, ejecutado en Colab. \n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <omp.h>    // Cabecera OpenMP   \n",
        "  \n",
        "int main(int argc, char* argv[]) \n",
        "{\n",
        "  int i,j=0;\n",
        "  std::cout<<\"Inicio...\"<<std::endl;\n",
        "\n",
        "  //-----------------------------------------------------------------------------------------------\n",
        "  // Region paralela\n",
        "  #pragma omp parallel\n",
        "  { \n",
        "    std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \", de \"<<  omp_get_num_threads() <<\", procesadores \"<< omp_get_num_procs()<< std::endl;  \n",
        "\n",
        "    #pragma omp single\n",
        "    {\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \" uno de muchos.\"<< std::endl;\n",
        "    }\n",
        "    #pragma omp master\n",
        "    {\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo maestro: \" << omp_get_thread_num()<< std::endl;\n",
        "    }\n",
        "\n",
        "    #pragma omp for schedule(dynamic, 5) lastprivate(j)\n",
        "    for(i=0;i<20;i++)\n",
        "    {\n",
        "      j++;\n",
        "      std::cout<<\"Hola mundo!!!... soy el hilo \" << omp_get_thread_num()<< \", itero para i .\"<<i<<\", actualizo j \"<<j<< std::endl;\n",
        "    }\n",
        "  }\n",
        "  // Region paralela\n",
        "  //-----------------------------------------------------------------------------------------------\n",
        "\n",
        "  std::cout<<\"Fin..., con j=\"<<j<<std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting code.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2CUqGa2NSPh"
      },
      "source": [
        "### 1.1.3 Compilación de Hola Mundo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLk4a5lTnOEI"
      },
      "source": [
        "!g++ -o hello -fopenmp code.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO--9RYTNe91"
      },
      "source": [
        "### 1.1.4. Ejecución Hola Mundo en OpenMP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98G8IH-NnGHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f588055-ae1d-4560-a6d6-ef61f5a28895"
      },
      "source": [
        "%env OMP_NUM_THREADS=5\n",
        "!./hello"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OMP_NUM_THREADS=5\n",
            "Inicio...\n",
            "Hola mundo!!!... soy el hilo Hola mundo!!!... soy el hilo 20, de , de 55, procesadores , procesadores 22\n",
            "Hola mundo!!!... soy el hilo 2 uno de muchos.\n",
            "\n",
            "Hola mundo!!!... soy el hilo 4, de 5, procesadores 2\n",
            "Hola mundo!!!... soy el hilo 1, de 5, procesadores 2\n",
            "Hola mundo!!!... soy el hilo 3, de 5, procesadores 2\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .0, actualizo j 1\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .1, actualizo j 2\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .2, actualizo j 3\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .3, actualizo j 4\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .4, actualizo j 5\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .5, actualizo j 6\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .6, actualizo j 7\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .7, actualizo j 8\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .8, actualizo j 9\n",
            "Hola mundo!!!... soy el hilo 3, itero para i .9, actualizo j 10\n",
            "Hola mundo!!!... soy el hilo maestro: 0\n",
            "Hola mundo!!!... soy el hilo 1, itero para i .15, actualizo j 1\n",
            "Hola mundo!!!... soy el hilo 1, itero para i .16, actualizo j 2\n",
            "Hola mundo!!!... soy el hilo 1, itero para i .17, actualizo j 3\n",
            "Hola mundo!!!... soy el hilo 1, itero para i .18, actualizo j 4\n",
            "Hola mundo!!!... soy el hilo 1, itero para i .19, actualizo j 5\n",
            "Hola mundo!!!... soy el hilo 4, itero para i .10, actualizo j 1\n",
            "Hola mundo!!!... soy el hilo 4, itero para i .11, actualizo j 2\n",
            "Hola mundo!!!... soy el hilo 4, itero para i .12, actualizo j 3\n",
            "Hola mundo!!!... soy el hilo 4, itero para i .13, actualizo j 4\n",
            "Hola mundo!!!... soy el hilo 4, itero para i .14, actualizo j 5\n",
            "Fin..., con j=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PQxHPkDdo42"
      },
      "source": [
        "---\n",
        "## 1.2. Ejercicio 2 - Axpy\n",
        "\n",
        "La función Axpy es parte de las bibliotecas BLAS [3]. Ella se encarga de realizar la suma de vectores, con la siguiente ecuación:\n",
        "\n",
        "<center>$Y = \\alpha X + Y$</center>\n",
        "\n",
        "En donde:\n",
        "> $\\alpha$: Es un escala.\n",
        "\n",
        "> $X$: Es el vector origen.\n",
        "\n",
        "> $Y$: Es el vector destino.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Preguntas Ejercicio 2\n",
        "a) Ejecute el ejercicio 1.2.2:\n",
        "\n",
        "    - Con la variable cantidad_N para: 50, 500, 5.000.\n",
        "    - Con los valores hilos_ 2, 4, 6.\n",
        "\n",
        "b) Repita la prueba (a), con ciclos 1, 10, 30. ¿Cuál fue la diferencia?\n",
        "\n",
        "c) ¿Por qué el SpeedUp no mejora a medida que aumentan la cantidad de hilos?\n",
        "\n",
        "d) ¿Qué sucede con la eficiencia a medida que aumentan la cantidad_N?¿Porqué no llega al valor ideal?."
      ],
      "metadata": {
        "id": "wHjoeL_wLguS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respuestas Ejercicio 2\n",
        "\n",
        "a)\n",
        "En la ejecución con valor de N 5000 y 2 hilos, el tiempo de la función por OMP fue más rápido que el tiempo por secuencial. En el resto de los casos, el tiempo de ejecución secuencial siempre fue más rápido. Si se utilizan 2 hilos, en los casos donde N vale 50 y 500, pese a ser más lento, la diferencia es de 0.07 milisegundos. Para cuando se ejecuta con 4 hilos o 6 hilos, la diferencia puede variar desde 1 milisegundo (caso N 500 y 6 threads) a 5 milisegundos (caso N 5000 y 6 threads).\n",
        "\n",
        "b)\n",
        "CON 30 CICLOS:\n",
        "*   N 50: El valor del overhead al utilizar 4 hilos se redujo en 11 unidades. El valor del overhead al utilizar 6 hilos aumentó en 2 unidades. El valor del overhead al utilizar 2 hilos fue casi el mismo.\n",
        "*   N 500: El valor del overhead al utilizar 2 hilos aumentó un total de 34 unidades. El overhead al utilizar 4 hilos aumentó apenas 1 unidad. Mientras que el del 6 se duplicó comparado a su valor en 10 ciclos.\n",
        "*   N 5000: si se utilizan 4 hilos, el valor del overhead se reduce en 5 unidades. Al usarse 6 hilos, aumenta en 5 unidades. Si se utilizan 2, el overhead aumenta en 30 unidades. \n",
        "\n",
        "CON 100 CICLOS:\n",
        "*   N 50: el valor del overhead al utilizar cualquier cantidad de hilos incrementa en gran medida a comparación con 10 ciclos. El overhead más alto cuando se usaron 10 ciclos fue de 13, mientras que el más alto fue de 23.\n",
        "*   N 500: El overhead se inrementa demasiado al utilizar 100 ciclos. Al ejecutar con 10, el overhead más alto llega a 2.88, mientras que el más bajo al ejecutar con 100, es de 6.21. \n",
        "*   N 5000: al utilizar 100 ciclos, el overhead para todos los casos se incrementa. Siendo el incremento más pequeño al ejecutar con 6 hilos (aumenta 7 unidades) mientras que con 2 hilos aumenta 27.\n",
        "\n",
        "c)\n",
        "Para que el speed up pueda mejorar, se tiene que lograr que el tiempo que tarda en ejecutar la función Axpy en paralelo sea menor al tiempo que tarda en ejecutar de forma secuencial. No importa cuantos hilos se dediquen a ejecutar dicha función de forma paralela, el tiempo que tarda en procesar de manera secuencial es siempre más rápido, por lo que el speed up no va a mejorar. Incluso hay casos donde aumentar la cantidad de hilos hace que el tiempo demore todavía más. En las ejecuciones que se hicieron, usar 4 hilos demora más que usar 2, y usar 8 demora más que usar 4. Por esto mismo, el speed up únicamente va a disminuir. \n",
        "\n",
        "d)\n",
        "Al ir incrementando el valor de N, el tiempo secuencial que tarda en ejecutar la función no se ve muy afectado (con N 50 y 2 hilos tarda 0.01 ms mientras que con N 5000 tarda 0.71 ms). En cambio, el tiempo que demora en ejecutar de forma paralela, con N 50 era de 2 ms mientras que al incrementarlo a N 5000 me llegó a dar una demora de 120 ms. El tiempo que tarda al aumentarse el valor de N se incrementa, pero es uno mucho mayor cuando la función ejecuta de forma paralela. Esto no hace más que disminuir el speed up. La eficiencia depende del speed up, dado a que en colab, el número de procesadores que tengo siempre será de 2, para obtener mejor eficiencia, es obligatorio mejorar el speed up. Algo que no ocurre al incrementar el valor de N.  "
      ],
      "metadata": {
        "id": "37j8Gvjazc_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Código Lenguaje C "
      ],
      "metadata": {
        "id": "wxsaxk7FSkmh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLE3iWiJsM0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b0668d-8031-4cda-ebb9-042f6b96dfe0"
      },
      "source": [
        "%%writefile code_axpy.cpp\n",
        "// Axpy con OpenMP, usando c, ejecutado en Colab. \n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <sys/time.h>\n",
        "#include <omp.h>    // Cabecera OpenMP   \n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "// Macros que miden el tiempo.\n",
        "\n",
        "static double dHashTiempoHistory[3];\n",
        "static struct timeval tv;\n",
        "\n",
        "#define TIEMPO_INI( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = tv.tv_sec + tv.tv_usec/1000000.0;\n",
        "   \n",
        "   \n",
        "#define TIEMPO_FIN( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = ((tv.tv_sec + tv.tv_usec/1000000.0) - dHashTiempoHistory[ h ]) * 1000; // Devuelvo en milisegundos\n",
        "#define TIEMPO_GET( h ) dHashTiempoHistory[ h ]\n",
        "\n",
        "#define HTH_TOTAL         1\n",
        "#define HTH_AXPY_SEC      2\n",
        "#define HTH_AXPY_OMP      3\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "void axpy( double alfa, vector<double> &X, vector<double> &Y )\n",
        "{\n",
        "  int i;\n",
        "\n",
        "  #pragma omp parallel for\n",
        "  for(i=0;i<Y.size();i++)\n",
        "  {\n",
        "    Y[i] = alfa * X[i] + Y[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "int main(int argc, char* argv[]) \n",
        "{ \n",
        "  int i,c;\n",
        "  TIEMPO_INI( HTH_TOTAL )\n",
        "\n",
        "  // Leo los parametros.\n",
        "  if( argc != 4 )\n",
        "  {\n",
        "      std::cerr<< \" Error en los parametros de indicar: (alfa), (Tamanio vector), (ciclos ejecucion).\"<<argc<<std::endl;\n",
        "      exit( -1 );\n",
        "  }\n",
        "\n",
        "  float alfa     = atof( argv[1] );\n",
        "  int cantidad_N = atoi( argv[2] );\n",
        "  int ciclos     = atoi( argv[3] );\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Defino la memoria de los vectores.\n",
        "\n",
        "  vector<double> X( cantidad_N );\n",
        "  vector<double> Y( cantidad_N );\n",
        "\n",
        "  for (int i=0;i<X.size();i++)\n",
        "  {\n",
        "    X[i] = (rand()/(double)RAND_MAX)*0.73;\n",
        "    Y[i] = (rand()/(double)RAND_MAX)*0.71;\n",
        "  }\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Realizo la función Axpy con OpenMP.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_OMP )\n",
        "\n",
        "  for(c=0;c<ciclos;c++)\n",
        "  {\n",
        "    axpy( alfa, X, Y );\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_OMP )\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Realizo la función Axpy en forma secuencial.\n",
        "\n",
        "  omp_set_num_threads(1);\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_SEC )\n",
        "\n",
        "  for(c=0;c<ciclos;c++)\n",
        "  {\n",
        "    axpy( alfa, X, Y );\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_SEC )\n",
        "\n",
        "  TIEMPO_FIN( HTH_TOTAL )\n",
        "\n",
        " std::cout<<\"Valores Reales  :\" <<std::endl;\n",
        " std::cout<<\"Tiempo TOTAL     : \"<<TIEMPO_GET(HTH_TOTAL   )<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"Valores Ideal: \"<<std::endl;\n",
        " TIEMPO_GET(HTH_AXPY_OMP) = TIEMPO_GET(HTH_AXPY_SEC) / omp_get_num_procs();\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        "\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        "}\n",
        "// ----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing code_axpy.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ClX3MgbLn2m"
      },
      "source": [
        "### 1.2.3. Compilación de código C Axpy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2PUrH_7tKUS"
      },
      "source": [
        "!g++ -o axpy -fopenmp code_axpy.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po1U26ujLs1I"
      },
      "source": [
        "### 1.2.4. Ejecución Axpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qt_B3jHuHyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6459fb35-94e3-4667-d38c-ca74333a5195"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "Cantidad_N = 5000#@param {type: \"number\"}\n",
        "Alfa       = 1.0#@param {type: \"number\"}\n",
        "Ciclos     = 10#@param {type: \"slider\", min: 10, max: 200}\n",
        "Hilos      = 2#@param {type: \"slider\", min: 1, max: 10}\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "%env OMP_NUM_THREADS=$Hilos\n",
        "!./axpy $Alfa $Cantidad_N $Ciclos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OMP_NUM_THREADS=2\n",
            "Valores Reales  :\n",
            "Tiempo TOTAL     : 121.442 [ms]\n",
            "Tiempo axpy Sec  : 0.714064 [ms]\n",
            "Tiempo axpy Omp  : 120.439 [ms]\n",
            "\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 0.714064 / 120.439 = 0.00592884\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 0.00592884 / 2 = 0.00296442\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 0.714064 = 0.714064\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 120.439 = 240.878\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 240.878 - 0.714064 = 240.164\n",
            "\n",
            "Valores Ideal: \n",
            "Tiempo axpy Sec  : 0.714064 [ms]\n",
            "Tiempo axpy Omp  : 0.357032 [ms]\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 0.714064 / 0.357032 = 2\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 2 / 2 = 1\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 0.714064 = 0.714064\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 0.357032 = 0.714064\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 0.714064 - 0.714064 = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aL0jXjFGn9C"
      },
      "source": [
        "---\n",
        "# Medidas de prestaciones en algoritmos paralelos\n",
        "Las técnicas de HPC buscan reducir los tiempos de ejecución, el tiempo como medida, no alcanza. Dos algoritmos pueden ejecutar en el mismo tiempo, pero uno de ellos usa menos procesadores [6,7]. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJxlhR-PHc4M"
      },
      "source": [
        "## SpeedUp\n",
        "Referencia a la ganancia de velocidad que se consigue con un algoritmo paralelo, al resolver el mismo problema con respecto al algoritmo secuencial.\n",
        "\n",
        "<center>$ SpeedUp = \\frac{Tiempo\\_Secuencial}{Tiempo\\_Paralelo} $</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBsWMz-fIEaW"
      },
      "source": [
        "##Eficiencia\n",
        "La eficiencia normaliza el valor del SpeedUp, al dividirlo por la cantidad de procesadores que se utilizaron para alcanzar la ganancia en velocidad. Dando la idea de la porción de tiempo que los procesadores se dedican al trabajo útil.\n",
        "\n",
        "<center>$ Eficiencia = \\frac{SpeedUp}{Nro\\_Procesadores} $</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feerSPFJI4UV"
      },
      "source": [
        "## Coste\n",
        "El coste de un algoritmo paralelo representa el tiempo realizado por todo el sistema en la resolución del problema.\n",
        "\n",
        "<center>$ coste = Nro\\_Procesadores \\times Tiempo\\_Algoritmo$</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-B-4e3gJWp2"
      },
      "source": [
        "## Función Overhead\n",
        "Es la diferencia entre el Coste y el tiempo secuencial. Mientras mayor es la función overhead, peor es el comportamiento del algoritmo paralelo.\n",
        "\n",
        "<center>$ Overhead = {Coste}-{Tiempo\\_Secuencial} $</center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tk2gqAyQKy_"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4IHd-IqdvT1"
      },
      "source": [
        "---\n",
        "# Bibliografía\n",
        "[1] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[3] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n",
        "\n",
        "[4] F. Almeida, D. Gimenéz, A. Vidal - Introducción a la programación paralela - 2008 - Editorial Parafino.\n",
        "\n",
        "[5] D. Jiménez-González - Introducción a las arquitecturas paralelas. [PDF](http://progc-unlam.com.ar/material-clase/OpenMP-MPI/Introducci%C3%B3n%20a%20la%20Computaci%C3%B3n%20Paralela.pdf)"
      ]
    }
  ]
}